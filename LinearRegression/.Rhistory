retail<-read.csv(file.choose())
View(retail)
table(retail$Outlet_Size,retail$Outlet_Type)
table(retail$Outlet_Size,retail$Outlet_Location_Type)
levels(retail$Outlet_Type)<-c(1,2,3,4)
retail[which(retail$Outlet_Type==1 & retail$Outlet_Size==""),"Outlet_Size"]<-"Small"
retail[which(retail$Outlet_Type==2 & retail$Outlet_Size==""),"Outlet_Size"]<-"Small"
View(retail)
levels(retail$Outlet_Size)
table(retail$Outlet_Type)
factor(retail$Outlet_Size)
library(plyr)
library(plyr)
retail$Outlet_Size<-mapvalues(retail$Outlet_Size,from=c("Small","Medium","High"),to=c(1,2,3))
View(retail)
levels(retail$Outlet_Location_Type)<-c(1,2,3)
View(retail)
levels(retail$Item_Fat_Content)
levels(retail$Item_Fat_Content)<-c("Low Fat","Low Fat","Low Fat","Regular","Regular")
View(retail)
retail$Item_Fat_Content<-mapvalues(retail$Item_Fat_Content,from=c("Low Fat","Regular"),to=c(1,2))
View(retail)
retail$Outlet_Establishment_Year<-2017-retail$Outlet_Establishment_Year
View(retail)
retail_1<-retail[,-c(1,5,7)]
View(retail_1)
set.seed(123)
set.seed(123)
random<-sample(x=c("Train","Test"),size=nrow(retail_1),replace=T,prob = c(0.7,0.3))
random
Training<-retail_1[random=="Train",]
View(Train)
Testing<-retail_1[random=="Test",]
set.seed(123)
random<-sample(x=c("Train","Test"),size=nrow(retail_1),replace=T,prob = c(0.7,0.3))
random
Train<-retail_1[random=="Train",]
View(Train)
Test<-retail_1[random=="Test",]
View(Test)
Train_model<-lm(Item_Outlet_Sales~.,data=Train)
summary(Train_model)
Train_model_1<-step(object=Train_model,direction="both")
summary(Train_model_1)
library(car)
vif(Training_model_1)
vif(Train_model_1)
durbin.watson(Train_model_1)
qqnorm(Train_model_1$residuals)
qqline(Train_model_1$residuals)
shapiro.test(Train_model_1$residuals) # errors are not normal
par(mfrow=c(2,2))
plot(Training_model_1) #heteroelasdicity present we need to apply log transform to make variance of errors constant
plot(Train_model_1) #heteroelasdicity present we need to apply log transform to make variance of errors constant
Train_model<-lm(log(Item_Outlet_Sales)~.,data=Train)
summary(Train_model)
Train_model_1<-step(object=Train_model,direction="both")
summary(Train_model_1)
Test_predict<-predict.lm(object=Train_model_1,newdata=Test)
summary(Test_predict)
cor(x=Test_predict,y=Test$Item_Outlet_Sales)
plot(Test$Item_Outlet_Sales,y=Test_predict)
plot(log(Test$Item_Outlet_Sales),y=Test_predict)
str(Titanic)
View(Titanic)
df<-as.data.frame(Titanic)
head(df)
titanic.raw<-NULL
for(i in 1:4){
titanic.raw<-cbind(titanic.raw,rep(as.character(df[,i]),df$Freq))
}
titanic.raw<-as.data.frame(titanic.raw)
titanic.raw<-as.data.frame(titanic.raw)
names(titanic.raw)<-names(df)[1:4]
dim(titanic.raw)
summary(titanic.raw)
library(arules)
rules.all<-apriori(titanic.raw)
inspect(rules.all)
rules<-apriori(titanic.raw,control=list(verbose=F),parameter = list(minlen=2, supp=0.005, conf=0.8),appearance = list(rhs=c("Survived=No", "Survived=Yes"),default="lhs"))
quality(rules) <- round(quality(rules), digits=3)
quality(rules) <- round(quality(rules), digits=3)
rules.sorted <- sort(rules, by="lift")
inspect(rules.sorted)
subset.matrix <- is.subset(rules.sorted, rules.sorted)
subset.matrix[lower.tri(subset.matrix, diag=T)] <- NA
subset.matrix[lower.tri(subset.matrix, diag=T)]<-NA
redundant <- colSums(subset.matrix, na.rm=T)>= 1
which(redundant)
rules.pruned <- rules.sorted[!redundant]
inspect(rules.pruned)
rules.pruned <- rules.sorted[!redundant]
inspect(rules.pruned)
library(ElemStatLearn)
library(leaps)
library(caret)
library(corrplot)
data("prostate")
str(prostate)
plot(prostate)
plot(prostate$gleason)
table(prostate$gleason)
boxplot(prostate$lpsa~prostate$gleason,xlab="Gleason Score",ylab="Log PSA")
prostate$gleason=ifelse(prostate$gleason==6,0,1)
table(prostate$gleason)
p.cor=cor(prostate)
corrplot.mixed(p.cor)
train=subset(prostate,train==TRUE)[,1:9]
str(train)
test=subset(prostate,train==FALSE)[,1:9]
str(test)
subfit=regsubsets(lpsa~.,data=train)
b.sum=summary(subfit)
which.min(b.sum$bic)
plot(subfit,scale="bic",main="Best Subset Features")
ols=lm(lpsa~lcavol+lweight+gleason,data=train)
plot(ols$fitted.values,train$lpsa)
pred.subfit=predict(ols,newdata=test)
resid.subfit=test$lpsa-pred.subfit
mean(resid.subfit^2)
x=as.matrix(train[,1:8])
x=as.matrix(train[,1:8])
y=train[,9]
x
y
ridge=glmnet(x,y,family="gaussian",alpha=0)
library(glmnet)
ridge=glmnet(x,y,family="gaussian",alpha=0)
print(ridge)
plot(ridge,label=TRUE)
plot(ridge,xvar="lambda",label="TRUE")
ridge.coef=coef(ridge,s=0.1,exact=TRUE)
ridge.coef
plot(ridge,xvar="dev",label=TRUE)
newx=as.matrix(test[,1:8])
ridge.y=predict(ridge,newx=newx,type="response",s=0.1)
plot(ridge.y,test$lpsa)
ridge.resid=ridge.y-test$lpsa
mean(ridge.resid^2)
lasso=glmnet(x,y,family = "gaussian",alpha=1)
print(lasso)
plot(lasso,xvar="lambda",label="TRUE")
lasso.coef(lasso,s=0.045,exact=TRUE)
lasso.coef=coef(lasso,s=0.045,exact=TRUE)
lasso.coef
lasso.y=predict(lasso,newx=newx,type="response",s=0.045)
plot(lasso.y,test$lpsa)
lasso.resid=lasso.y-test$lpsa
mean(lasso.resid^2)
library(caret)
library(caret)
library(caret)
library(caret)
grid=expand.grid(.aplha=seq(0,1,by=0.2), .lambda=seq(0.00,0.2,by=0.02))
table(grid)
control=trainControl(method="LOOCV")
elnet.train=train
elnet.train=train(lpsa~.,data=train,method="glmnet",trcontrol=control,)
elnet.train=train(lpsa~.,data=train,method="glmnet",trcontrol=control,tuneGrid=grid)
enet.train=train(lpsa~.,data=train,method="glmnet",trcontrol=control,tuneGrid=grid)
train=subset(prostate,train==TRUE)[,1:9]
library(ElemStatLearn)
library(leaps)
library(caret)
library(corrplot)
data("prostate")
str(prostate)
plot(prostate)
plot(prostate$gleason)
table(prostate$gleason)
boxplot(prostate$lpsa~prostate$gleason,xlab="Gleason Score",ylab="Log PSA")
prostate$gleason=ifelse(prostate$gleason==6,0,1)
table(prostate$gleason)
p.cor=cor(prostate)
corrplot.mixed(p.cor)
train=subset(prostate,train==TRUE)[,1:9]
str(train)
test=subset(prostate,train==FALSE)[,1:9]
str(test)
subfit=regsubsets(lpsa~.,data=train)
b.sum=summary(subfit)
which.min(b.sum$bic)
plot(subfit,scale="bic",main="Best Subset Features")
ols=lm(lpsa~lcavol+lweight+gleason,data=train)
plot(ols$fitted.values,train$lpsa)
pred.subfit=predict(ols,newdata=test)
plot(pred.subfit,test$lpsa)
resid.subfit=test$lpsa-pred.subfit
mean(resid.subfit^2)
x=as.matrix(train[,1:8])
y=train[,9]
x
y
library(glmnet)
ridge=glmnet(x,y,family="gaussian",alpha=0)
print(ridge)
plot(ridge,label=TRUE)
plot(ridge,xvar="lambda",label="TRUE")
ridge.coef=coef(ridge,s=0.1,exact=TRUE)
ridge.coef
plot(ridge,xvar="dev",label=TRUE)
newx=as.matrix(test[,1:8])
ridge.y=predict(ridge,newx=newx,type="response",s=0.1)
plot(ridge.y,test$lpsa)
ridge.resid=ridge.y-test$lpsa
mean(ridge.resid^2)
lasso=glmnet(x,y,family = "gaussian",alpha=1)
print(lasso)
plot(lasso,xvar="lambda",label="TRUE")
lasso.coef=coef(lasso,s=0.045,exact=TRUE)
lasso.coef
lasso.y=predict(lasso,newx=newx,type="response",s=0.045)
plot(lasso.y,test$lpsa)
lasso.resid=lasso.y-test$lpsa
mean(lasso.resid^2)
library(caret)
grid=expand.grid(.aplha=seq(0,1,by=0.2), .lambda=seq(0.00,0.2,by=0.02))
table(grid)
control=trainControl(method="LOOCV")
enet.train=train(lpsa~.,data=train,method="glmnet",trcontrol=control,tuneGrid=grid)
grid=expand.grid(.aplha=seq(0,1,by=0.2), .lambda=seq(0.00,0.2,by=0.02))
table(grid)
control=trainControl(method="LOOCV")
enet.train=train(lpsa~.,data=train,method="glmnet",trcontrol=control,tuneGrid=grid)
grid=expand.grid(aplha=seq(0,1,by=0.2), lambda=seq(0.00,0.2,by=0.02))
table(grid)
control=trainControl(method="LOOCV")
enet.train=train(lpsa~.,data=train,method="glmnet",trcontrol=control,tuneGrid=grid)
enet.train=train(lpsa~.,data=train,method="glmnet",trcontrol=control,tuneGrid=grid)
enet.train=train(lpsa~.,data=train,method="glmnet",trcontrol=control,tuneGrid=grid)
grid=expand.grid(.aplha=seq(0,1,by=0.2), .lambda=seq(0.00,0.2,by=0.02))
table(grid)
control=trainControl(method="LOOCV")
enet.train=train(lpsa~.,data=train,method="glmnet",trcontrol=control,tuneGrid=grid)
grid1=expand.grid(.aplha=seq(0,1,by=0.2), .lambda=seq(0.00,0.2,by=0.02))
table(grid1)
table(grid1)
control=trainControl(method="LOOCV")
enet.train=train(lpsa~.,data=train,method="glmnet",trcontrol=control,tuneGrid=grid1)
enet=glmnet(x,y,family = "gaussian",aplha=0,lamda=0.08)
enet=glmnet(x,y,family = "gaussian",alpha=0,lambda=0.08)
enet.coef=coef(enet,s=0.08,exact="TRUE")
enet.coef=coef(enet,s=0.08,exact="TRUE")
enet=glmnet(x,y,family = "gaussian",alpha=0,lambda=0.08)
enet.coef=coef(enet,s=0.08,exact="TRUE")
enet.coef=coef(enet,s=.08,exact="TRUE")
enet.coef=coef(enet,s=.08,exact="TRUE")
install.packages("h2o")
if ("package:h2o" %in% search()) { detach("package:h2o", unload=TRUE) }
if ("h2o" %in% rownames(installed.packages())) { remove.packages("h2o") }
pkgs <- c("statmod","RCurl","jsonlite")
for (pkg in pkgs) {
if (! (pkg %in% rownames(installed.packages()))) { install.packages(pkg) }
}
install.packages("h2o", type="source", repos="http://h2o-release.s3.amazonaws.com/h2o/rel-weierstrass/1/R")
install.packages("h2o", type="source", repos="http://h2o-release.s3.amazonaws.com/h2o/rel-weierstrass/1/R")
